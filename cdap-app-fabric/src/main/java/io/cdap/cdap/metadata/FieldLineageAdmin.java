/*
 * Copyright Â© 2018-2019 Cask Data, Inc.
 *
 * Licensed under the Apache License, Version 2.0 (the "License"); you may not
 * use this file except in compliance with the License. You may obtain a copy of
 * the License at
 *
 * http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS, WITHOUT
 * WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied. See the
 * License for the specific language governing permissions and limitations under
 * the License.
 */

package io.cdap.cdap.metadata;

import com.google.common.annotations.VisibleForTesting;
import com.google.common.base.Strings;
import com.google.common.collect.ImmutableSet;
import com.google.inject.Inject;
import io.cdap.cdap.api.data.schema.Schema;
import io.cdap.cdap.api.lineage.field.EndPoint;
import io.cdap.cdap.api.lineage.field.Operation;
import io.cdap.cdap.api.lineage.field.ReadOperation;
import io.cdap.cdap.api.lineage.field.TransformOperation;
import io.cdap.cdap.api.lineage.field.WriteOperation;
import io.cdap.cdap.api.metadata.MetadataEntity;
import io.cdap.cdap.api.metadata.MetadataScope;
import io.cdap.cdap.common.app.RunIds;
import io.cdap.cdap.common.conf.Constants;
import io.cdap.cdap.data2.metadata.lineage.field.DefaultFieldLineageReader;
import io.cdap.cdap.data2.metadata.lineage.field.EndPointField;
import io.cdap.cdap.data2.metadata.lineage.field.FieldLineageInfo;
import io.cdap.cdap.data2.metadata.lineage.field.FieldLineageReader;
import io.cdap.cdap.proto.id.DatasetId;
import io.cdap.cdap.proto.id.ProgramId;
import io.cdap.cdap.proto.id.ProgramReference;
import io.cdap.cdap.proto.id.ProgramRunId;
import io.cdap.cdap.proto.metadata.lineage.DatasetField;
import io.cdap.cdap.proto.metadata.lineage.EndpointsSummary;
import io.cdap.cdap.proto.metadata.lineage.Field;
import io.cdap.cdap.proto.metadata.lineage.FieldLineageDetails;
import io.cdap.cdap.proto.metadata.lineage.FieldLineageSummary;
import io.cdap.cdap.proto.metadata.lineage.FieldOperationInfo;
import io.cdap.cdap.proto.metadata.lineage.FieldOperationInput;
import io.cdap.cdap.proto.metadata.lineage.FieldOperationOutput;
import io.cdap.cdap.proto.metadata.lineage.ProgramFieldOperationInfo;
import io.cdap.cdap.proto.metadata.lineage.ProgramInfo;
import io.cdap.cdap.proto.metadata.lineage.ProgramRunOperations;
import io.cdap.cdap.spi.metadata.MetadataConstants;
import java.io.IOException;
import java.util.ArrayList;
import java.util.Collections;
import java.util.HashMap;
import java.util.HashSet;
import java.util.List;
import java.util.Map;
import java.util.Set;
import java.util.concurrent.TimeUnit;
import java.util.stream.Collectors;
import java.util.stream.Stream;
import javax.annotation.Nullable;
import org.apache.twill.api.RunId;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

/**
 * Service to compute field lineage based on operations stored in {@link
 * DefaultFieldLineageReader}.
 */
public class FieldLineageAdmin {

  private static final Logger LOG = LoggerFactory.getLogger(FieldLineageAdmin.class);

  private final FieldLineageReader fieldLineageReader;
  private final MetadataAdmin metadataAdmin;

  @Inject
  @VisibleForTesting
  public FieldLineageAdmin(FieldLineageReader fieldLineageReader, MetadataAdmin metadataAdmin) {
    this.fieldLineageReader = fieldLineageReader;
    this.metadataAdmin = metadataAdmin;
  }

  /**
   * Get the set of fields written to the EndPoint by field lineage {@link WriteOperation}, over the
   * given time range, optionally filtered to include only fields that have the given prefix.
   * Additionally, can include fields from the dataset schema if those field are not present in
   * lineage information for complete and coherent information about fields.
   *
   * @param endPoint the EndPoint for which the fields need to be returned
   * @param start start time (inclusive) in milliseconds
   * @param end end time (exclusive) in milliseconds
   * @param prefix prefix for the field name, if {@code null} then all fields are returned
   * @param includeCurrent determines whether to include dataset's current schema fields in the
   *     response. If true the result will be a union of all the fields present in lineage record
   *     with {@link Field#hasLineage} set to 'true' and fields present only in dataset schema will
   *     have {@link Field#hasLineage} set to 'false'.
   * @return set of fields written to a given EndPoint and any unique fields present only in the
   *     schema of the dataset of includeCurrent is set to true
   */
  public Set<Field> getFields(EndPoint endPoint, long start, long end, @Nullable String prefix,
      boolean includeCurrent) throws IOException {

    Set<String> lineageFields = fieldLineageReader.getFields(endPoint, start, end);

    Set<Field> result = createFields(lineageFields, true);
    if (includeCurrent) {
      result.addAll(createFields(getFieldsWithNoFieldLineage(endPoint, lineageFields), false));
    }
    return Strings.isNullOrEmpty(prefix) ? Collections.unmodifiableSet(result) :
        Collections.unmodifiableSet(filter(prefix, result));
  }

  /**
   * Get the summary for the specified EndPointField over a given time range depending on the
   * direction specified. Summary in the "incoming" direction consists of set of EndPointFields
   * which participated in the computation of the given EndPointField; summary in the "outgoing"
   * direction consists of set of EndPointFields which were computed from the specified
   * EndPointField. When direction is specified as 'both', incoming as well as outgoing summaries
   * are returned.
   *
   * @param direction the direction in which summary need to be computed
   * @param endPointField the EndPointField for which summary to be returned
   * @param start start time (inclusive) in milliseconds
   * @param end end time (exclusive) in milliseconds
   * @return the FieldLineageSummary
   */
  FieldLineageSummary getFieldLineage(Constants.FieldLineage.Direction direction,
      EndPointField endPointField,
      long start, long end) {
    Set<DatasetField> incoming = null;
    Set<DatasetField> outgoing = null;
    if (direction == Constants.FieldLineage.Direction.INCOMING
        || direction == Constants.FieldLineage.Direction.BOTH) {
      Set<EndPointField> incomingSummary = fieldLineageReader.getIncomingSummary(endPointField,
          start, end);
      incoming = convertSummaryToDatasetField(incomingSummary);
    }
    if (direction == Constants.FieldLineage.Direction.OUTGOING
        || direction == Constants.FieldLineage.Direction.BOTH) {
      Set<EndPointField> outgoingSummary = fieldLineageReader.getOutgoingSummary(endPointField,
          start, end);
      outgoing = convertSummaryToDatasetField(outgoingSummary);
    }
    return new FieldLineageSummary(incoming, outgoing);
  }

  /**
   * Get the summary for the specified dataset over a given time range depending on the direction
   * specified. The summary will contain all the field level lineage relations about all the fields
   * in a dataset.
   *
   * @param direction the direction in which summary need to be computed
   * @param endPoint the EndPoint whicn represents the dataset that field level lineage needs to
   *     get computed
   * @param start start time (inclusive) in milliseconds
   * @param end end time (exclusive) in milliseconds
   * @return the summary which contains all the field level lineage information about all the fields
   *     in a dataset
   * @throws IOException if fails to get teh schema of the dataset
   */
  public DatasetFieldLineageSummary getDatasetFieldLineage(
      Constants.FieldLineage.Direction direction,
      EndPoint endPoint,
      long start, long end) throws IOException {
    Set<String> lineageFields = fieldLineageReader.getFields(endPoint, start, end);
    Map<DatasetId, Set<FieldRelation>> incomingRelations = new HashMap<>();
    Map<DatasetId, Set<FieldRelation>> outgoingRelations = new HashMap<>();
    Map<DatasetId, Integer> fieldCount = new HashMap<>();
    for (String field : lineageFields) {
      EndPointField endPointField = new EndPointField(endPoint, field);

      // compute the incoming field level lineage
      if (direction == Constants.FieldLineage.Direction.INCOMING
          || direction == Constants.FieldLineage.Direction.BOTH) {
        Map<DatasetId, Set<String>> incomingSummary =
            convertSummaryToDatasetMap(
                fieldLineageReader.getIncomingSummary(endPointField, start, end));
        // compute the field count for all incoming datasets
        incomingSummary.keySet().forEach(datasetId -> {
          fieldCount.computeIfAbsent(
              datasetId,
              missingDataset -> missingDataset == null ? 0 : fieldLineageReader.getFields(
                  EndPoint.of(missingDataset.getNamespace(), missingDataset.getDataset()), start,
                  end).size());
        });
        // here the field itself will be the destination
        computeAndAddRelations(incomingRelations, field, true, incomingSummary);
      }

      // compute the outgoing field level lineage
      if (direction == Constants.FieldLineage.Direction.OUTGOING
          || direction == Constants.FieldLineage.Direction.BOTH) {
        Map<DatasetId, Set<String>> outgoingSummary =
            convertSummaryToDatasetMap(
                fieldLineageReader.getOutgoingSummary(endPointField, start, end));
        // compute the field count for all outgoing datasets
        outgoingSummary.keySet().forEach(datasetId -> {
          fieldCount.computeIfAbsent(
              datasetId,
              missingDataset -> missingDataset == null ? 0 : fieldLineageReader.getFields(
                  EndPoint.of(missingDataset.getNamespace(), missingDataset.getDataset()), start,
                  end).size());
        });
        // here the field itself will be the source
        computeAndAddRelations(outgoingRelations, field, false, outgoingSummary);
      }
    }

    Set<String> noLineageFields = getFieldsWithNoFieldLineage(endPoint, lineageFields);
    Set<String> allFields = ImmutableSet.<String>builder().addAll(lineageFields)
        .addAll(noLineageFields).build();
    return new DatasetFieldLineageSummary(direction, start, end,
        new DatasetId(endPoint.getNamespace(), endPoint.getName()),
        allFields, fieldCount, incomingRelations, outgoingRelations);
  }

  /**
   * Compute the relations from the given summary and add the field relation to the map of
   * relations. The field is either the source or the destination in the relation.
   */
  private void computeAndAddRelations(Map<DatasetId, Set<FieldRelation>> relations, String field,
      boolean isDestination,
      Map<DatasetId, Set<String>> summary) {
    for (Map.Entry<DatasetId, Set<String>> entry : summary.entrySet()) {
      DatasetId outgoing = entry.getKey();
      relations.computeIfAbsent(outgoing, k -> new HashSet<>());
      entry.getValue().forEach(otherField -> relations.get(outgoing).add(
          isDestination ? new FieldRelation(otherField, field)
              : new FieldRelation(field, otherField)));
    }
  }

  private Set<DatasetField> convertSummaryToDatasetField(Set<EndPointField> summary) {
    Map<DatasetId, Set<String>> endPointFields = convertSummaryToDatasetMap(summary);

    Set<DatasetField> result = new HashSet<>();
    for (Map.Entry<DatasetId, Set<String>> entry : endPointFields.entrySet()) {
      result.add(new DatasetField(entry.getKey(), entry.getValue()));
    }

    return result;
  }

  private Map<DatasetId, Set<String>> convertSummaryToDatasetMap(Set<EndPointField> summary) {
    Map<DatasetId, Set<String>> endPointFields = new HashMap<>();
    for (EndPointField endPointField : summary) {
      EndPoint endPoint = endPointField.getEndPoint();
      // this can be null if the field is not related to any dataset, it can either be generated or dropped
      DatasetId datasetId = (endPoint.getNamespace() == null || endPoint.getName() == null) ? null :
          new DatasetId(endPoint.getNamespace(), endPoint.getName());
      Set<String> fields = endPointFields.computeIfAbsent(datasetId, k -> new HashSet<>());
      fields.add(endPointField.getField());
    }
    return endPointFields;
  }

  /**
   * Get the operation details for the specified EndPointField over a given time range depending on
   * the direction specified. Operation details in the "incoming" direction consists of consists of
   * the datasets and their fields ({@link DatasetField}) that this field originates from, as well
   * as the programs and operations that generated this field from those origins. In outgoing
   * direction, it consists of the datasets and their fields ({@link DatasetField}) that were
   * computed from this field, along with the programs and operations that performed the
   * computation. When direction is specified as 'both', incoming as well as outgoing operations are
   * returned.
   *
   * @param direction the direction in which operations need to be computed
   * @param endPointField the EndPointField for which operations to be returned
   * @param start start time (inclusive) in milliseconds
   * @param end end time (exclusive) in milliseconds
   * @return the FieldLineageDetails instance
   */
  FieldLineageDetails getOperationDetails(Constants.FieldLineage.Direction direction,
      EndPointField endPointField,
      long start, long end) {
    List<ProgramFieldOperationInfo> incoming = null;
    List<ProgramFieldOperationInfo> outgoing = null;
    if (direction == Constants.FieldLineage.Direction.INCOMING
        || direction == Constants.FieldLineage.Direction.BOTH) {
      List<ProgramRunOperations> incomingOperations = fieldLineageReader.getIncomingOperations(
          endPointField, start,
          end);
      incoming = processOperations(incomingOperations);
    }
    if (direction == Constants.FieldLineage.Direction.OUTGOING
        || direction == Constants.FieldLineage.Direction.BOTH) {
      List<ProgramRunOperations> outgoingOperations = fieldLineageReader.getOutgoingOperations(
          endPointField, start,
          end);
      outgoing = processOperations(outgoingOperations);
    }
    return new FieldLineageDetails(incoming, outgoing);
  }

  private Set<String> getFieldsWithNoFieldLineage(EndPoint dataset,
      Set<String> lineageFields) throws IOException {
    // get the system properties of this dataset
    Map<String, String> properties = metadataAdmin.getProperties(MetadataScope.SYSTEM,
        MetadataEntity.ofDataset(dataset.getNamespace(),
            dataset.getName()));
    // the system metadata contains the schema of the dataset which is written by the DatasetSystemMetadataWriter
    if (properties.containsKey(MetadataConstants.SCHEMA_KEY)) {
      String schema = properties.get(MetadataConstants.SCHEMA_KEY);
      Schema sc = Schema.parseJson(schema);
      if (sc.getFields() != null) {
        Set<String> schemaFields = sc.getFields().stream().map(Schema.Field::getName)
            .collect(Collectors.toSet());
        // filter out the fields that are part of the lineageFields
        return sc.getFields().stream()
            .map(Schema.Field::getName)
            .filter(name -> !lineageFields.contains(name))
            .collect(Collectors.toSet());
      }
    } else {
      LOG.trace(
          "Received request to include schema fields for {} but no schema was found. Only fields present in "

              + "the lineage store will be returned.", dataset);
    }
    return Collections.emptySet();
  }

  private List<ProgramFieldOperationInfo> processOperations(
      List<ProgramRunOperations> programRunOperations) {
    List<ProgramFieldOperationInfo> result = new ArrayList<>();
    for (ProgramRunOperations entry : programRunOperations) {
      List<ProgramInfo> programInfo = computeProgramInfo(entry.getProgramRunIds());
      List<FieldOperationInfo> fieldOperationInfo = computeFieldOperationInfo(
          entry.getOperations());
      result.add(new ProgramFieldOperationInfo(programInfo, fieldOperationInfo));
    }
    return result;
  }

  /**
   * Computes the list of {@link ProgramInfo} from given set of ProgramRunIds. For each program,
   * there is only one item in the returned list, representing the latest run of that program.
   * Returned list is also sorted by the last executed time in descending order.
   *
   * @param programRunIds set of program run ids from which program info to be computed
   * @return list of ProgramInfo
   */
  private List<ProgramInfo> computeProgramInfo(Set<ProgramRunId> programRunIds) {
    Map<ProgramId, Long> programIdToLastExecutedTime = new HashMap<>();
    for (ProgramRunId programRunId : programRunIds) {
      long programRunExecutedTime = RunIds.getTime(programRunId.getRun(), TimeUnit.SECONDS);
      Long lastExecutedTime = programIdToLastExecutedTime.get(programRunId.getParent());
      if (lastExecutedTime == null || programRunExecutedTime > lastExecutedTime) {
        programIdToLastExecutedTime.put(programRunId.getParent(), programRunExecutedTime);
      }
    }

    Stream<Map.Entry<ProgramId, Long>> sortedByLastExecutedTime =
        programIdToLastExecutedTime.entrySet().stream()
            .sorted(Collections.reverseOrder(Map.Entry.comparingByValue()));

    List<ProgramInfo> programInfos;

    programInfos = sortedByLastExecutedTime.map(
        programIdLongEntry -> new ProgramInfo(programIdLongEntry.getKey(),
            programIdLongEntry.getValue())).collect(Collectors.toList());

    return programInfos;
  }

  /**
   * Computes list of {@link FieldOperationInfo} from the given operations. Returned list contains
   * the operations sorted in topological order i.e. each operation in the list is guaranteed to
   * occur before any other operation that reads its outputs.
   *
   * @param operations set of operation to convert to FieldOperationInfo instances
   * @return list of FieldOperationInfo sorted topologically
   */
  private List<FieldOperationInfo> computeFieldOperationInfo(Set<Operation> operations) {
    List<Operation> orderedOperations = FieldLineageInfo.getTopologicallySortedOperations(
        operations);
    List<FieldOperationInfo> fieldOperationInfos = new ArrayList<>();
    for (Operation operation : orderedOperations) {
      fieldOperationInfos.add(convertToFieldOperationInfo(operation));
    }

    return fieldOperationInfos;
  }

  private FieldOperationInfo convertToFieldOperationInfo(Operation operation) {
    FieldOperationInput inputs = null;
    FieldOperationOutput outputs = null;
    switch (operation.getType()) {
      case READ:
        ReadOperation read = (ReadOperation) operation;
        inputs = FieldOperationInput.of(read.getSource());
        outputs = FieldOperationOutput.of(read.getOutputs());
        break;
      case TRANSFORM:
        TransformOperation transform = (TransformOperation) operation;
        inputs = FieldOperationInput.of(transform.getInputs());
        outputs = FieldOperationOutput.of(transform.getOutputs());
        break;
      case WRITE:
        WriteOperation write = (WriteOperation) operation;
        inputs = FieldOperationInput.of(write.getInputs());
        outputs = FieldOperationOutput.of(write.getDestination());
        break;
    }
    return new FieldOperationInfo(operation.getName(), operation.getDescription(), inputs, outputs);
  }

  private Set<Field> createFields(Set<String> fields, boolean hasLineage) {
    return fields.stream().map(field -> new Field(field, hasLineage)).collect(Collectors.toSet());
  }

  private Set<Field> filter(String prefix, Set<Field> fields) {
    return fields.stream().filter(field ->
            field.getName().toLowerCase().startsWith(prefix.toLowerCase()))
        .collect(Collectors.toSet());
  }

  /**
   * Retrieves a summary of all endpoints in a given program run.
   *
   * @param namespaceId program namespace
   * @param programReference start time of the run in millis corresponding to the id of a
   *     program run
   * @param runId run ID which is a UUID
   * @return Summary of all Endpoints in the particular run of the pipeline.
   */
  public EndpointsSummary getEndpoints(String namespaceId, ProgramReference programReference,
      RunId runId) {
    return new EndpointsSummary(
        fieldLineageReader.getEndpoints(namespaceId, programReference, runId));
  }
}
